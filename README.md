# Design and Development of Automatic Indian Sign Language to Telugu Speech Conversion Using LSTM
Objective: Developed an innovative model using Long Short Term Memory (LSTM) networks to convert Indian Sign Language (ISL) hand gestures into Telugu speech, bridging the communication gap between hearing and speech-impaired individuals and Telugu speakers.
Data Collection & Preprocessing: Created a dataset by recording video sequences of ISL gestures. Implemented key points extraction using MediaPipe to obtain hand, face, and pose landmarks with high accuracy.
Model Development: Trained an LSTM-based Recurrent Neural Network (RNN) to learn long-term dependencies in gesture sequences, effectively translating ISL gestures into textual format.
Text-to-Speech Conversion: Utilized Googleâ€™s text-to-speech API and the Festival Speech Synthesis System to convert translated text into natural-sounding Telugu speech, optimizing prosody and speech quality.
Results: Achieved high gesture recognition accuracy and developed a fully functional prototype that enhances accessibility for Telugu-speaking communities.
